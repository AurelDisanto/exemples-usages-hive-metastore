{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f4a41-121d-4ee7-8d9c-43ba5f414499",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45651fd-2745-4532-9183-af99c1037681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "from graphframes import *\n",
    "import pickle\n",
    "from pyspark.sql.functions import col,explode,size,first\n",
    "from pyspark.sql.functions import udf, collect_list\n",
    "from pyspark.sql.functions import count,collect_list,flatten\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85e842-9401-4ec9-8545-5399c40d6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "\n",
    "#url par défaut d'une api kubernetes accédé depuis l'intérieur du cluster (ici le notebook tourne lui même dans kubernetes)\n",
    "conf.setMaster(\"k8s://https://kubernetes.default.svc:443\")\n",
    "\n",
    "#image des executors spark: pour des raisons de simplicité on réutilise l'image du notebook\n",
    "conf.set(\"spark.kubernetes.container.image\", os.environ['IMAGE_NAME'])\n",
    "\n",
    "# Nom du compte de service pour contacter l'api kubernetes : attention le package du datalab crée lui même cette variable d'enviromment.\n",
    "# Dans un pod du cluster kubernetes il faut lire le fichier /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "# Néanmoins ce paramètre est inutile car le contexte kubernetes local de ce notebook est préconfiguré\n",
    "# conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \n",
    "\n",
    "# Nom du namespace kubernetes\n",
    "conf.set(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\n",
    "\n",
    "# Nombre d'executeur spark, il se lancera autant de pods kubernetes que le nombre indiqué.\n",
    "conf.set(\"spark.executor.instances\", \"10\")\n",
    "\n",
    "# Mémoire alloué à la JVM\n",
    "# Attention par défaut le pod kubernetes aura une limite supérieur qui dépend d'autres paramètres.\n",
    "# On manipulera plus bas pour vérifier la limite de mémoire totale d'un executeur\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "conf.set(\"spark.kubernetes.driver.pod.name\", os.environ['KUBERNETES_POD_NAME'])\n",
    "\n",
    "# Paramètres d'enregistrement des logs spark d'application\n",
    "# Attention ce paramètres nécessitent la création d'un dossier spark-history. Spark ne le fait pas lui même pour des raisons obscurs\n",
    "# import s3fs\n",
    "# endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "# fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint})\n",
    "# fs.touch('s3://tm8enk/spark-history/.keep')\n",
    "# sparkconf.set(\"spark.eventLog.enabled\",\"true\")\n",
    "# sparkconf.set(\"spark.eventLog.dir\",\"s3a://tm8enk/spark-history\")\n",
    "#ici pour gérer le dateTimeFormatter dépendant de la verion de java...\n",
    "conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "conf.set(\"spark.default.parallelism\",10)\n",
    "conf.set(\"spark.sql.shuffle.partitions\",10)\n",
    "conf.set(\"spark.jars.packages\",\"graphframes:graphframes:0.8.1-spark3.0-s_2.12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6745c2c-034a-4081-8f30-c30d1e90e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"graph\").config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915f403-724b-4a19-911c-7a16d3b8b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = [(1,\"A\"), (2,\"B\"), (3, \"C\")]\n",
    "edges = [(1,2,\"love\"), (2,1,\"hate\"), (2,3,\"follow\")]\n",
    "\n",
    "v = spark.createDataFrame(vertices, [\"id\", \"name\"])\n",
    "e = spark.createDataFrame(edges, [\"src\", \"dst\", \"action\"])\n",
    "\n",
    "premierGraphe = GraphFrame(v, e)\n",
    "premierGraphe.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7beed6-9b7a-42f7-9cda-c5dce7377223",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pickle.load(open(\"/home/onyxia/work/schema.p\", \"rb\" ))\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb698f2-26b4-4083-85d4-cc2092c7b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\")  \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"s3a://projet-spark-lab/diffusion/tweets/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae82e8-cfcd-4d1e-894d-630c0e21172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col(\"id\").alias(\"id\"),\n",
    "         col(\"user.id\").alias(\"user_id\"),\n",
    "         col(\"user.name\").alias(\"name\"),\n",
    "         col(\"user.followers_count\"),\n",
    "         col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "         size(\"entities.hashtags\").alias(\"has_hashtag\"),\n",
    "         col(\"text\"),\n",
    "         col(\"entities.user_mentions\")) \\\n",
    " .filter(col(\"has_hashtag\")>0) \\\n",
    " .head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a70be-38ef-4440-aaa5-d0cd042e11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeters=df.select(col(\"user.id\").alias(\"id\"), col(\"user.name\").alias(\"name\"))\n",
    "users_mentionned=df.select(explode(col(\"entities.user_mentions\"))).select(col(\"col.id\").alias(\"id\"),col(\"col.screen_name\").alias(\"name\")).distinct()\n",
    "vertices=tweeters.union(users_mentionned)\n",
    "# on définit un udf qui prend le premier élément\n",
    "udf_first = udf(lambda x: x[0])\n",
    "# on groupe l'union des deux dataset par id d'utilisateur et on collect \n",
    "#sous la forme d'une liste leurs noms qui peuvent différer entre les mentions et le compte\n",
    "# on applique l'udf pour ne retenir que le nom en tête\n",
    "final_vertices=vertices.groupby(\"id\").agg(udf_first(collect_list(\"name\")).alias(\"name\"))\n",
    "final_vertices.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f600b21e-63f8-4b95-b466-ab9cd0f94a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=====================================================>(957 + 1) / 958]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---+--------+--------------------+\n",
      "|    src|               dst| nb|hashtags|                  id|\n",
      "+-------+------------------+---+--------+--------------------+\n",
      "|1012981|973130412628246529|  1|      []|[1385318639994290...|\n",
      "|1349111|         217473382|  1|      []|[1426382322706919...|\n",
      "|1536651|          17510568|  1|      []|[1382995514933850...|\n",
      "|1745171|          16649457|  1|      []|[1436253710137667...|\n",
      "|3639301|        4041503175|  1|      []|[1386964092682964...|\n",
      "|4478161|         217473382|  1|      []|[1433405191211130...|\n",
      "|4478161|        3077516146|  1|      []|[1394763627283066...|\n",
      "|5523462|         268227446|  1|      []|[1394285638040567...|\n",
      "|5891532|           5788732|  1|      []|[1394724638886875...|\n",
      "|6274062|         200659061|  1|      []|[1425104376738336...|\n",
      "+-------+------------------+---+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edges=df.select(col(\"user.id\").alias(\"user_id\"), \\\n",
    "               explode(col(\"entities.user_mentions\")).alias(\"mention\"),\n",
    "               col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "               \"id\") \\\n",
    " .groupby(col(\"user_id\").alias(\"src\"), \\\n",
    "          col(\"mention.id\").alias(\"dst\")) \\\n",
    " .agg(count(\"id\").alias(\"nb\"),\n",
    "      flatten(collect_list(\"hashtags\")).alias(\"hashtags\"),\n",
    "      collect_list(\"id\").alias(\"id\"))\n",
    "edges.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f086e8-7f5f-4ffe-b3b6-28836eef1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphFrame(final_vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6ffed-161e-42a9-9209-df9fb8c8f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d19a91-0a6c-45f1-bcef-db5485232852",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"le graphe a \"+ str(g.vertices.count()) +\" noeuds et \"+ str(g.edges.count()) + \" arcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b3042-dd6c-4499-8609-008ff4323725",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = g.pageRank(resetProbability=0.15,tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b866581-9eb0-4b0b-8f58-c27de1322ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank.vertices.sort(desc(\"pagerank\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe9f3e-eafe-4ca9-b1cd-9316902ea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank.edges.where((col(\"src\")==\"103918784\") ).show(truncate=False)\n",
    "pagerank.edges.where((col(\"dst\")==\"103918784\") ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b045ac-9e36-4a1a-a23d-0ccd3dc2f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.join(g.vertices,\"id\").orderBy(desc(\"inDegree\")).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fda9c-a04f-4c89-b294-4cf1ab4566ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.outDegrees.join(g.vertices,\"id\").orderBy(desc(\"outDegree\")).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26dabcc-e860-44ba-894b-2748a0383369",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
